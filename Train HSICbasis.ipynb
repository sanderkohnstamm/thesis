{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d62fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Subset, ChainDataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import HSIC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import func\n",
    "import torchy\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# functions to show an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd954d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"PACS.pkl\", \"rb\")\n",
    "feature_dict = pickle.load(a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52860af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "DATASETS_NAMES = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "CLASSES_NAMES = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "DOMAIN_DICT = {'photo':[1,0,0,0], 'art_painting':[0,1,0,0], 'cartoon':[0,0,1,0], 'sketch':[0,0,0,1]}\n",
    "\n",
    "data_sets = {}\n",
    "data_loaders = {}\n",
    "\n",
    "training_names = ['photo', 'art_painting', 'cartoon']\n",
    "\n",
    "data, l, domains = func.dict_to_data(feature_dict, training_names, DOMAIN_DICT) \n",
    "train_loader= DataLoader(torchy.Dataset(data, l, domains), batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "\n",
    "\n",
    "valid_names = ['sketch']\n",
    "\n",
    "data, l, domains = func.dict_to_data(feature_dict, valid_names, DOMAIN_DICT) \n",
    "valid_loader = DataLoader(torchy.Dataset(data, l, domains), batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchy.Net()\n",
    "print(net)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481fc0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loaders = [data_loaders['photo'], data_loaders['art_painting']]\n",
    "validate_loader = data_loaders['cartoon']\n",
    "# print(len(data_loaders['photo']), len(data_loaders['art']))\n",
    "func.trainHSIC(net, criterion, optimizer, train_loaders, validate_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f626ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(data_loaders['sketch'])\n",
    "features, labels = dataiter.next()\n",
    "\n",
    "\n",
    "print('GroundTruth: ', ' '.join(f'{CLASSES_NAMES[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "outputs = net(features)\n",
    "\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{CLASSES_NAMES[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72034f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "\n",
    "\n",
    "# test_loader = cartoon_dataloader\n",
    "test_loader = data_loaders['sketch']\n",
    "# test_loader = cartoon_dataloader\n",
    "PATH = 'saved_model.pth'\n",
    "test_net = torchy.Net()\n",
    "test_net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        features, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = test_net(features)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_loader)} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2347c72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
