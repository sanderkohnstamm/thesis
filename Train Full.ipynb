{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07717c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Subset, ChainDataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "\n",
    "import HSIC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import func\n",
    "import torchy\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from matplotlib import cm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import wandb\n",
    "\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148df091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added :cartoon, length: 2344\n",
      "Added :art_painting, length: 2048\n",
      "Added :photo, length: 1670\n",
      "Added :sketch, length: 3929\n"
     ]
    }
   ],
   "source": [
    "data_root = \"../../Data/PACS/\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# print(dict(Counter(dataset.targets)))\n",
    "num_classes = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "all_domain_names = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "domain_names = ['photo', 'art_painting', 'cartoon']\n",
    "classes_names = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "domain_mapping = {'photo':0, 'art_painting':1, 'cartoon':2, 'sketch':3}\n",
    "model_path = 'saved_model.pth'\n",
    "\n",
    "\n",
    "train_names = ['photo', 'art_painting']\n",
    "valid_name = ['cartoon']\n",
    "test_name = 'split'\n",
    "\n",
    "# means and standard deviations ImageNet because the network is pretrained\n",
    "means, stds = (0.485, 0.456, 0.406), (0.229, 0.224, 0.225)\n",
    "\n",
    "# Define transforms to apply to each image\n",
    "transf = transforms.Compose([ #transforms.Resize(227),      # Resizes short size of the PIL image to 256\n",
    "                            transforms.CenterCrop(224),  # Crops a central square patch of the image 224 because torchvision's AlexNet needs a 224x224 input!\n",
    "                            transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n",
    "                            transforms.Normalize(means,stds) # Normalizes tensor with mean and standard deviation\n",
    "])\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "for name in os.listdir(data_root):\n",
    "\n",
    "    if not name[0] == '.':\n",
    "        dataset = torchvision.datasets.ImageFolder(data_root+name, transform=transf)\n",
    "\n",
    "        datasets[name] = dataset\n",
    "        print(f\"Added :{name}, length: {len(datasets[name])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273d7df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:  0.2\n",
      "0\n",
      "Training on ['art_painting', 'cartoon']\n",
      "Validation on trainingset split\n",
      "Testing on ['photo']\n",
      "Using HSIC:True\n",
      "Cuda:cpu\n",
      "Epoch 0\n",
      "HSIC: tensor(0.6603, grad_fn=<DivBackward0>)\n",
      "Training loss: tensor(4.8645, grad_fn=<AddBackward0>)\n",
      "Validation Loss Decreased(1000.000000--->163.408525) \t Saving The Model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/00wq4rm50pn_293hhfwwx6_40000gn/T/ipykernel_47381/1930198582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         min_valid_loss = func.train(net, criterion, optimizer, \n\u001b[0m\u001b[1;32m     59\u001b[0m                                     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                                     \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Thesis/Code_git/thesis/func.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(net, criterion, optimizer, train_loader, epochs, gamma, device, valid_loader, use_hsic, writer, min_valid_loss, verbose, wb)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# gc.collect() # Python thing\n",
    "# torch.cuda.empty_cache() # PyTorch thing\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_names = ['art_painting', 'cartoon']\n",
    "valid_name = 'split'\n",
    "test_name = ['photo']\n",
    "\n",
    "lr=0.0001\n",
    "use_hsic = True\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "verbose = True\n",
    "now = datetime.now()\n",
    "current_time = now.strftime(\"%H_%M_%S\")\n",
    "\n",
    "\n",
    "for gamma in [0.2]:\n",
    "    print('gamma: ', gamma)\n",
    "    for i in range(2):\n",
    "        print(i)\n",
    "        \n",
    "        current_time = now.strftime(\"%H_%M_%S\")\n",
    "#         wandb.init(project=f\"colab_runs_embeddings\",\n",
    "#                     entity=\"skohnie\",\n",
    "#                     name=f'{current_time}/{gamma}/{i}',\n",
    "#                     config = {\"learning_rate\": lr,\n",
    "#                                 \"epochs\": epochs,\n",
    "#                                 \"batch_size\": batch_size,\n",
    "#                                 \"gamma\": gamma,\n",
    "#                                 \"Train names\": train_names,\n",
    "#                                 \"Valid name\": valid_name,\n",
    "#                                 \"Test name\": test_name\n",
    "#                                 }\n",
    "#                 )\n",
    "\n",
    "\n",
    "\n",
    "        train_loader, valid_loader, test_loader  = torchy.get_image_loaders(datasets, \n",
    "                                                                            batch_size,\n",
    "                                                                            train_names,\n",
    "                                                                            valid_name,\n",
    "                                                                            test_name,\n",
    "                                                                            verbose=verbose)\n",
    "\n",
    "\n",
    "        resnet18 = models.resnet18(pretrained=True)\n",
    "        net = torchy.CustomNet(resnet18)\n",
    "\n",
    "\n",
    "        min_valid_loss = 1000\n",
    "\n",
    "\n",
    "\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr) \n",
    "        min_valid_loss = func.train(net, criterion, optimizer, \n",
    "                                    train_loader,\n",
    "                                    valid_loader=valid_loader,\n",
    "                                    epochs=epochs,\n",
    "                                    use_hsic=use_hsic,\n",
    "                                    gamma=gamma,\n",
    "                                    device=device,\n",
    "                                    writer=None,\n",
    "                                    min_valid_loss = min_valid_loss,\n",
    "                                    wb=False,\n",
    "                                    verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "        _, _, acc = func.test_model(net, test_loader, 'saved_model.pth', verbose=True)\n",
    "        print(acc)\n",
    "#         wandb.log({'Testing accuracy': acc})\n",
    "#         wandb.summary['Test Accuracy'] = acc\n",
    "#         wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32dc4fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41ae045",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "DOMAIN_NAMES = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "CLASSES_NAMES = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "domain_mapping = {'photo':0, 'art_painting':1, 'cartoon':2, 'sketch':3}\n",
    "batch_size = 64\n",
    "PATH = 'saved_model.pth'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "lambd = 1\n",
    "i = 0\n",
    "\n",
    "# train_names = [DOMAIN_NAMES[1]]\n",
    "# valid_name = DOMAIN_NAMES[2]\n",
    "# test_name = DOMAIN_NAMES[0]\n",
    "# hsic_name =  DOMAIN_NAMES[3]\n",
    "\n",
    "train_names = DOMAIN_NAMES[1:]\n",
    "valid_name = 'split'\n",
    "test_name = DOMAIN_NAMES[0]\n",
    "hsic_name =  None\n",
    "\n",
    "train_loader, valid_loader, test_loader, HSIC_loader  = torchy.get_image_loaders(datasets,\n",
    "                                                                           batch_size,\n",
    "                                                                           train_names,\n",
    "                                                                           hsic_name,\n",
    "                                                                           valid_name,\n",
    "                                                                           test_name)\n",
    "\n",
    "\n",
    "# Display image and label.\n",
    "train_features, train_labels, _ = next(iter(train_loader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "images = train_features\n",
    "plt.imshow(torchvision.utils.make_grid(images, nrow=5).permute(1, 2, 0))\n",
    "plt.show()\n",
    "print(f\"Label: {train_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ac874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "acc_list = []                          \n",
    "min_valid_loss = 1000\n",
    "for lr in [0.02, 0.001]:\n",
    "    \n",
    "    resnet18 = models.resnet18(pretrained=True)\n",
    "    resnet18.fc1 = nn.Linear(512, 7)\n",
    "    \n",
    "    writer= SummaryWriter(f'runs/test_vis')\n",
    "    optimizer = optim.Adam(resnet18.parameters(), lr=lr)\n",
    "    min_valid_loss = func.train(resnet18, criterion, optimizer, train_loader,\n",
    "                                    valid_loader=valid_loader,\n",
    "                                    epochs=20,\n",
    "                                    HSIC_loader=HSIC_loader,\n",
    "                                    lambd=lambd,\n",
    "                                    writer=writer,\n",
    "                                    min_valid_loss = min_valid_loss)\n",
    "    writer.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10d1312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
