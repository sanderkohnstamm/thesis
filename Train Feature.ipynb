{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d62fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Subset, ChainDataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import random\n",
    "\n",
    "import HSIC\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import func\n",
    "import torchy\n",
    "\n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd954d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_file = open(\"PACS.pkl\", \"rb\")\n",
    "full_dict = pickle.load(a_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082deeec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d345949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_names = ['photo', 'art_painting', 'cartoon']\n",
    "\n",
    "data_list, labels = func.dict_to_data(full_dict, domain_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52860af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_domain_names = ['photo', 'art_painting', 'cartoon', 'sketch']\n",
    "domain_names = ['photo', 'art_painting', 'cartoon']\n",
    "\n",
    "# data_dict = {}\n",
    "# for name in domain_names:\n",
    "#     data_dict[name] = full_dict[name]\n",
    "    \n",
    "num_classes = 7      # 7 classes for each domain: 'dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person'\n",
    "classes_names = ['Dog', 'Elephant', 'Giraffe', 'Guitar', 'Horse', 'House', 'Person']\n",
    "domain_mapping = {'photo':0, 'art_painting':1, 'cartoon':2, 'sketch':3}\n",
    "model_path = 'saved_model.pth'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a6de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 3\n",
    "i = 0\n",
    "net = torchy.Net()\n",
    "lr=0.001\n",
    "use_hsic = True\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for lambd in [0, 1, 2, 3, 5, 8]:\n",
    "    print('Lambda: ', lambd)\n",
    "    i=0\n",
    "    for name in domain_names:\n",
    "        for name2 in domain_names:\n",
    "            if name == name2: \n",
    "                continue\n",
    "            train_names = [name, name2]\n",
    "            valid_name = [n for n in domain_names if n not in train_names]\n",
    "            test_name = 'split'\n",
    "\n",
    "            train_loader, valid_loader, test_loader  = torchy.get_feature_loaders(full_dict, \n",
    "                                                                                   batch_size,\n",
    "                                                                                   train_names,\n",
    "                                                                                   valid_name,\n",
    "                                                                                   test_name,\n",
    "                                                                                 verbose=False)\n",
    "\n",
    "\n",
    "            net = torchy.Net()\n",
    "\n",
    "            min_valid_loss = 1000\n",
    "\n",
    "            writer= SummaryWriter(f'runs/feature/lambda{lambd}/{i}/{use_hsic}')\n",
    "\n",
    "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "            min_valid_loss = func.train(net, criterion, optimizer, \n",
    "                                        train_loader,\n",
    "                                        valid_loader=valid_loader,\n",
    "                                        epochs=30,\n",
    "                                        use_hsic=use_hsic,\n",
    "                                        lambd=lambd,\n",
    "                                        writer=writer,\n",
    "                                        min_valid_loss = min_valid_loss)\n",
    "            writer.close()\n",
    "\n",
    "            acc = func.test_model(test_loader, 'saved_model.pth')\n",
    "            # acc_list.append(acc)\n",
    "            print(f'{i} Trained: {train_names}, Valid: {valid_name}, Testing: {test_name}, HSIC: {use_hsic}= {acc}%')\n",
    "            \n",
    "            i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966a2785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m API key must be 40 characters long, yours was 1859\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 993, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 241, in setup\n",
      "    wandb_login._login(\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 284, in _login\n",
      "    wlogin.prompt_api_key()\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 212, in prompt_api_key\n",
      "    key, status = self._prompt_api_key()\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 192, in _prompt_api_key\n",
      "    key = apikey.prompt_api_key(\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\", line 123, in prompt_api_key\n",
      "    write_key(settings, key, api=api)\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\", line 217, in write_key\n",
      "    api.clear_setting(\"anonymous\", globally=True, persist=True)\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/internal/internal_api.py\", line 264, in clear_setting\n",
      "    self._settings.clear(\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/old/settings.py\", line 69, in clear\n",
      "    clear_setting(self._global_settings, Settings._global_path(), persist)\n",
      "  File \"/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/old/settings.py\", line 65, in clear_setting\n",
      "    with open(settings_path, \"w+\") as f:\n",
      "PermissionError: [Errno 13] Permission denied: '/Users/sanderkohnstamm/.config/wandb/settings'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "problem",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_noop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             wandb_login._login(\n\u001b[0m\u001b[1;32m    242\u001b[0m                 \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anonymous\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, _backend, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 key = apikey.prompt_api_key(\n\u001b[0m\u001b[1;32m    193\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mwrite_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mwrite_key\u001b[0;34m(settings, key, api, anonymous)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anonymous\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36mclear_setting\u001b[0;34m(self, key, globally, persist)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclear_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         self._settings.clear(\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mSettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SECTION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobally\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobally\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/old/settings.py\u001b[0m in \u001b[0;36mclear\u001b[0;34m(self, section, key, globally, persist)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mglobally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mclear_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_settings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/old/settings.py\u001b[0m in \u001b[0;36mclear_setting\u001b[0;34m(settings, settings_path, persist)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Users/sanderkohnstamm/.config/wandb/settings'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/42/00wq4rm50pn_293hhfwwx6_40000gn/T/ipykernel_3973/4262055218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test_one\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"skohnie\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexcept_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"problem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_seen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/thesis/lib/python3.9/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: problem"
     ]
    }
   ],
   "source": [
    "net = torchy.Net()\n",
    "lr=0.001\n",
    "use_hsic = True\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "lambd=5\n",
    "\n",
    "\n",
    "wandb.init(project=\"test_one\", entity=\"skohnie\")\n",
    "\n",
    "\n",
    "train_names = ['photo', 'cartoon']\n",
    "valid_name = ['art_painting']\n",
    "test_name = 'split'\n",
    "\n",
    "# results =  {0:[], 5:[]}\n",
    "# for lambd in [0, 5]:\n",
    "#     print('Lambda: ', lambd)\n",
    "#     for i in range(10):\n",
    "train_loader, valid_loader, test_loader  = torchy.get_feature_loaders(full_dict, \n",
    "                                                                       batch_size,\n",
    "                                                                       train_names,\n",
    "                                                                       valid_name,\n",
    "                                                                       test_name,\n",
    "                                                                       verbose=False)\n",
    "\n",
    "\n",
    "net = torchy.Net()\n",
    "\n",
    "min_valid_loss = 1000\n",
    "\n",
    "# writer= SummaryWriter(f'runs/test_one/lambda{lambd}/{i}/{use_hsic}')\n",
    "wandb.config = {\n",
    "    \"learning_rate\": lr,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 128,\n",
    "    \"Lamda\": lambd,\n",
    "    \"Train names\": train_names,\n",
    "    \"Valid name\": valid_name,\n",
    "    \"Test name\": test_name\n",
    "}\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "min_valid_loss = func.train(net, criterion, optimizer, \n",
    "                            train_loader,\n",
    "                            valid_loader=valid_loader,\n",
    "                            epochs=30,\n",
    "                            use_hsic=use_hsic,\n",
    "                            lambd=lambd,\n",
    "                            writer=None,\n",
    "                            min_valid_loss = min_valid_loss,\n",
    "                            wb=True)\n",
    "\n",
    "acc = func.test_model(test_loader, 'saved_model.pth')\n",
    "print(acc)\n",
    "#         results[lambd].append(acc)\n",
    "        # acc_list.append(acc)\n",
    "# print(f'{i} Trained: {train_names}, Valid: {valid_name}, Testing: {test_name}, HSIC: {use_hsic}= {acc}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae66366",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array((results[0], results[5]))\n",
    "print(X)\n",
    "print(X.mean(axis=1))\n",
    "print(X.std(axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2127240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambd = 0\n",
    "i = 0\n",
    "\n",
    "train_names = [DATASETS_NAMES[0]]\n",
    "valid_name = [DATASETS_NAMES[1]]\n",
    "test_name = [DATASETS_NAMES[3]]\n",
    "HSIC_name = [DATASETS_NAMES[2]]\n",
    "train_loader, valid_loader, test_loader, HSIC_loader  = torchy.get_loaders(feature_dict, [DATASETS_NAMES[0]], DATASETS_NAMES, BATCH_SIZE, val_test_domains=True, \n",
    "                                                                                    with_hsic=with_hsic, valid_name=[DATASETS_NAMES[1]], test_name=[DATASETS_NAMES[2]])\n",
    "acc_list = []                          \n",
    "min_valid_loss = 1000\n",
    "for lr in [0.02, 0.001]:\n",
    "    net = torchy.Net()\n",
    "    writer= SummaryWriter(f'runs/test_bn/l:{lambd}/i:{i}/lr:{lr}')\n",
    "    i+=1\n",
    "    print(i)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "    min_valid_loss = func.trainHSIC(net, criterion, optimizer, train_loader,\n",
    "       validate_loader=valid_loader, epochs=20, HSIC_loader=HSIC_loader, lambd=lambd, writer=writer, min_valid_loss = min_valid_loss)\n",
    "    writer.close()\n",
    "\n",
    "acc = func.test_model(test_loader, 'saved_model.pth')\n",
    "acc_list.append(acc)\n",
    "print(f'Training: {train_names[0], HSIC_name[0] }, Valid: {valid_name[0]}, Testing: {test_name[0]} = {acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'saved_model.pth'\n",
    "test_net = torchy.Net()\n",
    "test_net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "test_net.eval()\n",
    "\n",
    "\n",
    "\n",
    "train_iter = iter(train_loader)\n",
    "HSIC_iter = iter(HSIC_loader)\n",
    "\n",
    "data, labels1, _ = train_iter.next()\n",
    "\n",
    "output = test_net(data)\n",
    "\n",
    "def normalize_output(img):\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    return img\n",
    "\n",
    "# Plot some images\n",
    "idx = torch.randint(0, output.size(0), ())\n",
    "pred = normalize_output(output)\n",
    "img = normalize_output(data)\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "print(img.shape)\n",
    "axarr[0].imshow(img.detach().numpy())\n",
    "axarr[1].imshow(pred.detach().numpy())\n",
    "\n",
    "# Visualize feature maps\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "print(test_net)\n",
    "\n",
    "test_net.fc2.register_forward_hook(get_activation('fc1'))\n",
    "data, labels1, _ = train_iter.next()\n",
    "data = data\n",
    "output = test_net(data)\n",
    "\n",
    "act = activation['fc1'].squeeze()\n",
    "fig, axarr = plt.subplots(1)\n",
    "axarr.imshow(act)\n",
    "\n",
    "data, labels1, _ = HSIC_iter.next()\n",
    "data = data\n",
    "output = test_net(data)\n",
    "\n",
    "act = activation['fc1'].squeeze()\n",
    "fig, axarr = plt.subplots(1)\n",
    "axarr.imshow(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc1.register_forward_hook(get_activation('fc1'))\n",
    "data, labels1, _ = train_iter.next()\n",
    "data = data\n",
    "output = net(data)\n",
    "\n",
    "act = activation['fc1'].squeeze()\n",
    "fig, axarr = plt.subplots(1)\n",
    "axarr.imshow(act)\n",
    "\n",
    "data, labels1, _ = HSIC_iter.next()\n",
    "data = data\n",
    "output = net(data)\n",
    "\n",
    "act = activation['fc1'].squeeze()\n",
    "fig, axarr = plt.subplots(1)\n",
    "axarr.imshow(act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6050295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69338b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcc128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62935d74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in [result_list1, result_list2, result_list3]:\n",
    "    plt.hist(l, label= ['0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.9'], bins=5)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Accuracy\", fontsize=16)  \n",
    "    plt.xticks(fontsize=14)  \n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb34cf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e1831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1-hsic\n",
    "result_list = [[65, 49, 74, 49, 74, 94, 69, 54, 94, 54, 94, 96, 61, 55, 93, 55, 93, 100, 66, 70, 93, 70, 93, 94], [68, 53, 74, 53, 74, 90, 67, 58, 94, 58, 94, 93, 61, 57, 94, 57, 94, 99, 64, 68, 93, 68, 93, 99], [65, 56, 75, 56, 75, 89, 69, 59, 94, 59, 94, 97, 66, 56, 93, 56, 93, 99, 63, 65, 95, 65, 95, 95], [63, 52, 75, 52, 75, 94, 72, 50, 91, 50, 91, 93, 65, 57, 95, 57, 95, 90, 65, 70, 93, 70, 93, 92], [61, 50, 73, 50, 73, 87, 68, 52, 93, 52, 93, 93, 63, 53, 92, 53, 92, 85, 65, 70, 94, 70, 94, 90]]\n",
    "\n",
    "plt.hist(result_list, label= [str(i) for i in [0, 0.5, 2, 8, 11]], bins=4)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Accuracy\", fontsize=16)  \n",
    "plt.xticks(fontsize=14)  \n",
    "plt.yticks(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3927e8ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a481fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer=None\n",
    "l=1\n",
    "for lr in [0.5, 0.1, 0.05, 0.02, 0.01]:\n",
    "    for l in [0]:\n",
    "        net = torchy.Net()\n",
    "        print(f'lr:{lr}_lam:{l}')\n",
    "        writer= SummaryWriter(f'runs/test/lr:{lr}_lam:{l}')\n",
    "        optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "        func.trainHSIC(net, criterion, optimizer, train_loader,\n",
    "           validate_loader=valid_loader, epochs=20, lambd=l, with_hsic=True, writer=writer)\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ea7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in [True, False]:\n",
    "    for lr in [0.05, 0.01, 0.005, 0.001]:\n",
    "        if t == True:\n",
    "            for l in [0, 0.1, 0.4, 0.9, 2]:\n",
    "                net = torchy.Net()\n",
    "                print(f'runs/{t}_lr:{lr}_lam:{l}')\n",
    "                writer= SummaryWriter(f'runs/pa_s/{t}_lr:{lr}_lam:{l}')\n",
    "                optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "                func.trainHSIC(net, criterion, optimizer,  train_loader,\n",
    "           validate_loader=valid_loader, epochs=20, lambd=l, with_hsic=t, writer=writer)\n",
    "                writer.close()\n",
    "        else:\n",
    "            net = torchy.Net()\n",
    "            print(f'runs/{t}_lr:{lr}')\n",
    "            writer= SummaryWriter(f'runs/pa_s/{t}_lr:{lr}')\n",
    "            optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "            func.trainHSIC(net, criterion, optimizer,  train_loader,\n",
    "           validate_loader=valid_loader, epochs=20, lambd=l, with_hsic=t, writer=writer)\n",
    "            writer.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f626ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchy.Net()\n",
    "\n",
    "writer= SummaryWriter(f'runs/pa_s/{t}_lr:{lr}')\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9)\n",
    "func.trainHSIC(net, criterion, optimizer,  train_loader,\n",
    "validate_loader=valid_loader, epochs=20, lambd=l, with_hsic=t, writer=writer)\n",
    "writer.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72034f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "\n",
    "\n",
    "# test_loader = cartoon_dataloader\n",
    "test_loader = data_loaders['sketch']\n",
    "# test_loader = cartoon_dataloader\n",
    "PATH = 'saved_model.pth'\n",
    "test_net = torchy.Net()\n",
    "test_net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        features, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = test_net(features)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the {len(test_loader)} test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897c17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "if True: print('bla')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d494444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
